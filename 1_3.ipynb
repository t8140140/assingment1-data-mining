{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import random    \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_table = pd.read_csv(filepath_or_buffer='./ml-1m/ratings.dat',\n",
    "                            sep='::', delimiter=None, header=0, engine='python')\n",
    "\n",
    "# 1.\n",
    "mean_rating_global = ratings_table['Rating'].mean()\n",
    "# 2.\n",
    "mean_rating_per_movie = ratings_table.groupby('MovieID')['Rating'].mean()\n",
    "# .3\n",
    "mean_rating_per_user = ratings_table.groupby('UserID')['Rating'].mean()\n",
    "\n",
    "\n",
    "def generate_X_set(columns, *features):\n",
    "    matrix = np.vstack(features[:2]).T\n",
    "    X_set = pd.DataFrame(data=matrix, columns=columns)\n",
    "    return X_set\n",
    "    \n",
    "X = generate_X_set(['UserID', 'MovieID'],*[ratings_table['UserID'], ratings_table['MovieID']])\n",
    "\n",
    "X_per_movie = generate_X_set(['MovieID', 'UserID'],*[ratings_table['UserID'], ratings_table['MovieID'], mean_rating_per_movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_global = X.copy()\n",
    "\n",
    "X_global['global_average'] = mean_rating_global\n",
    "\n",
    "X_per_user = pd.merge(left=X, right=mean_rating_per_user, how='left', \n",
    "              left_on='UserID', right_index=True)\n",
    "\n",
    "X_per_movie = pd.merge(left=X, right=mean_rating_per_movie, how='left', \n",
    "              left_on='MovieID', right_index=True)\n",
    "\n",
    "X_per_user_and_movie = pd.merge(left=X_per_user, right=mean_rating_per_movie, how='left', \n",
    "              left_on='MovieID', right_index=True)\n",
    "\n",
    "y = ratings_table['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import T\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def k_fold_split_training(X, y, intercept=False): \n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=32)\n",
    "    rmse_test = []\n",
    "    rmse_train = []\n",
    "    \n",
    "    mae_test = []\n",
    "    mae_train = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        linear_reg = LinearRegression(fit_intercept=intercept)\n",
    "\n",
    "        linear_reg.fit(X_train, y_train)\n",
    "        \n",
    "        y_predict_test = linear_reg.predict(X_test)\n",
    "        y_predict_train = linear_reg.predict(X_train)\n",
    "        \n",
    "        rmse_train.append(np.sqrt(mean_squared_error(y_train, y_predict_train)))\n",
    "        rmse_test.append(np.sqrt(mean_squared_error(y_test, y_predict_test)))\n",
    "        mae_train.append(mean_absolute_error(y_train, y_predict_train))\n",
    "        mae_test.append(mean_absolute_error(y_test, y_predict_test))\n",
    "\n",
    "    return np.sum(rmse_test)/5, np.sum(rmse_train)/5, np.sum(mae_test)/5, np.sum(mae_train)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse train:  [1.1147380346457683, 1.0263643938220377, 0.9747097226241838, 0.9442214366365042, 0.9155427386251869]\n",
      "rmse test:  [1.1147405104341572, 1.026366945489675, 0.9747135005426525, 0.9442245824478661, 0.9155464240466344]\n",
      "mae train:  [0.9301582475623554, 0.8213175634092712, 0.7787995924883884, 0.7565995537623753, 0.7258099996638087]\n",
      "mae test:  [0.9301598218103528, 0.8213185423861319, 0.7788031490903922, 0.7566016666222036, 0.7258125623984603]\n"
     ]
    }
   ],
   "source": [
    "total_rmses_train = []\n",
    "total_rmses_test = []\n",
    "total_maes_train = []\n",
    "total_maes_test = []\n",
    "\n",
    "rmse_test, rmse_train, mae_test, mae_train = k_fold_split_training(X_global, y)\n",
    "total_rmses_train.append(rmse_train)\n",
    "total_rmses_test.append(rmse_test)\n",
    "total_maes_train.append(mae_train)\n",
    "total_maes_test.append(mae_test)\n",
    "rmse_test, rmse_train, mae_test, mae_train = k_fold_split_training(X_per_user, y)\n",
    "total_rmses_train.append(rmse_train)\n",
    "total_rmses_test.append(rmse_test)\n",
    "total_maes_train.append(mae_train)\n",
    "total_maes_test.append(mae_test)\n",
    "rmse_test, rmse_train, mae_test, mae_train = k_fold_split_training(X_per_movie, y)\n",
    "total_rmses_train.append(rmse_train)\n",
    "total_rmses_test.append(rmse_test)\n",
    "total_maes_train.append(mae_train)\n",
    "total_maes_test.append(mae_test)\n",
    "rmse_test, rmse_train, mae_test, mae_train = k_fold_split_training(X_per_user_and_movie, y)\n",
    "total_rmses_train.append(rmse_train)\n",
    "total_rmses_test.append(rmse_test)\n",
    "total_maes_train.append(mae_train)\n",
    "total_maes_test.append(mae_test)\n",
    "rmse_test, rmse_train, mae_test, mae_train = k_fold_split_training(X_per_user_and_movie, y, True)\n",
    "total_rmses_train.append(rmse_train)\n",
    "total_rmses_test.append(rmse_test)\n",
    "total_maes_train.append(mae_train)\n",
    "total_maes_test.append(mae_test)\n",
    "\n",
    "print('rmse train: ', total_rmses_train)\n",
    "print('rmse test: ', total_rmses_test)\n",
    "print('mae train: ', total_maes_train)\n",
    "print('mae test: ', total_maes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_u_v(m):\n",
    "    u = np.full((m.shape[0],2), 1)\n",
    "    v = np.full((2,m.shape[1]), 1)\n",
    "    u = u.astype(np.float32)\n",
    "    v = v.astype(np.float32)\n",
    "    return u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(m): \n",
    "    Row_df = m.pivot(index = 'user_id', columns ='movie_id', values = 'rating')\n",
    "    u_mean = Row_df.mean(axis=1)\n",
    "    Row_df_array = Row_df.to_numpy()\n",
    "    u_mean = u_mean.to_numpy()\n",
    "    #creating a normal matrix to compare to our uv matrix\n",
    "    normal = Row_df_array - u_mean.reshape(-1,1)\n",
    "    N = normal\n",
    "    return N,Row_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_v(u,v,N):\n",
    "    sums = 0\n",
    "    u_ik = u[:,:]\n",
    "    v_ks = v[:,s]\n",
    "    u_ik_del = np.delete(u_ik, r, 1)\n",
    "    v_ks_del = np.delete(v_ks, r, 0)\n",
    "    u_ir = u[:,r]\n",
    "    u_ir_squared = u_ir ** 2\n",
    "    u_ik_v_ks = np.dot(u_ik_del, v_ks_del)\n",
    "    m_is = N[:,s]\n",
    "    error = m_is - u_ik_v_ks\n",
    "    uir_dot_er = u_ir * error\n",
    "    sumsv = np.nansum(uir_dot_er)\n",
    "    u_ir_ssum = np.nansum(u_ir_squared * (~np.isnan(m_is)))\n",
    "    newval_v =  sumsv / u_ir_ssum\n",
    "    v[r,s] = v[r,s] + ((newval_v - v[r,s]))\n",
    "    return u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(dif):\n",
    "    dif_abs= (np.absolute(dif))\n",
    "        #converting all nan values to a zero value.\n",
    "    dif_abs_0s = np.nan_to_num(dif_abs)\n",
    "    dif_abs_sum = np.sum(dif_abs_0s,axis=0)\n",
    "    sum_dif = dif_abs_sum.sum()\n",
    "    non_0_count = np.count_nonzero(dif_abs_0s)\n",
    "    MAE=sum_dif/non_0_count\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(dif):\n",
    "    dif_sqr = dif ** 2\n",
    "    dif_sqr_0s = np.nan_to_num(dif_sqr)\n",
    "    dif_sqr_total= np.sum( dif_sqr_0s ,axis=0)\n",
    "    sumz = dif_sqr_total.sum()\n",
    "    non_0_count_sqr = np.count_nonzero( dif_sqr_0s )\n",
    "    RMSE = sumz/ non_0_count_sqr\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheemo\\AppData\\Local\\Temp\\ipykernel_10608\\3931577527.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  u_mean = Row_df.mean(axis=1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [207], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m RT_train, RT_test \u001b[39m=\u001b[39m RT\u001b[39m.\u001b[39mloc[train_index], RT\u001b[39m.\u001b[39mloc[test_index]\n\u001b[0;32m     14\u001b[0m \u001b[39m#create a dataframe to store all ratings as values for each movie in a coloumn with every user id as index of the rows.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m normal,Row_df \u001b[39m=\u001b[39m normalize_data(RT_train)\n\u001b[0;32m     16\u001b[0m N \u001b[39m=\u001b[39m normal\n\u001b[0;32m     17\u001b[0m Row_df_array \u001b[39m=\u001b[39m Row_df\u001b[39m.\u001b[39mto_numpy()\n",
      "Cell \u001b[1;32mIn [206], line 7\u001b[0m, in \u001b[0;36mnormalize_data\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m      5\u001b[0m u_mean \u001b[39m=\u001b[39m u_mean\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m      6\u001b[0m \u001b[39m#creating a normal matrix to compare to our uv matrix\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m normal \u001b[39m=\u001b[39m Row_df_array \u001b[39m-\u001b[39;49m u_mean\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m N \u001b[39m=\u001b[39m normal\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m N,Row_df\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "# UV Decomposition - Training\n",
    "\n",
    "#input the path of ratings.dat file\n",
    "RT = pd.read_csv('./ml-1m/ratings.dat', engine='python', sep='::', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "#create a kfold function to divide the data into 5 random sets for cross validation\n",
    "KF = KFold(n_splits=5, shuffle=True, random_state=9)\n",
    "c = 2\n",
    "i = 5\n",
    "\n",
    "#start the iteration for each of the 5 folds\n",
    "for train_index, test_index in KF.split(RT):\n",
    "    RT_train, RT_test = RT.loc[train_index], RT.loc[test_index]\n",
    "    #create a dataframe to store all ratings as values for each movie in a coloumn with every user id as index of the rows.\n",
    "    normal,Row_df = normalize_data(RT_train)\n",
    "    N = normal\n",
    "    Row_df_array = Row_df.to_numpy()\n",
    "    #creating uv matrix components with u having n X d and v having d X m ( where n = number of users, m = number of movies and d = 2)\n",
    "    u,v = create_u_v(normal)\n",
    "    uv = np.dot(u,v)\n",
    "    print(\"Index:\", train_index)\n",
    "  # updating u using the formula x =(Σj vsj (mrj−Σk̸=surkvkj))/Σjv^2sj\n",
    "    for iterations in range(i):\n",
    "        for r in range(6040):\n",
    "            for s in range(c):\n",
    "                u,v = update_u(u,v,N)\n",
    "        #update v using the formula y = (Σiuir(mis−Σk̸=ruikvks))/Σiu^2ir\n",
    "        for r in range(c):\n",
    "            for s in range(Row_df_array.shape[1]):\n",
    "                u,v = update_v(u,v,N)\n",
    "        uv = np.dot(u,v)\n",
    "        dif = uv-normal\n",
    "        print(\"Iteration Number: \",iterations )\n",
    "        MAE = mae(dif)\n",
    "        print('MAE',MAE)\n",
    "        #calculating RMSE\n",
    "        RMSE = rmse(dif)\n",
    "        print('RMSE=',RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UV Decomposition - Test\n",
    "\n",
    "#input the path of ratings.dat file\n",
    "RT = pd.read_csv('ratings.dat', engine='python', sep='::', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "#create a kfold function to divide the data into 5 random sets for cross validation\n",
    "KF = KFold(n_splits=5, shuffle=True, random_state=9)\n",
    "c = 2\n",
    "i = 5\n",
    "\n",
    "#start the iteration for each of the 5 folds\n",
    "for train_index, test_index in KF.split(RT):\n",
    "    RT_train, RT_test = RT.loc[train_index], RT.loc[test_index]\n",
    "    #create a dataframe to store all ratings as values for each movie in a coloumn with every user id as index of the rows.\n",
    "    normal,Row_df = normalize_data(RT_test)\n",
    "    N = normal\n",
    "    Row_df_array = Row_df.to_numpy()\n",
    "    #creating uv matrix components with u having n X d and v having d X m ( where n = number of users, m = number of movies and d = 2)\n",
    "    u,v = create_u_v(normal)\n",
    "    uv = np.dot(u,v)\n",
    "    print(\"Index:\", test_index)\n",
    "  # updating u using the formula x =(Σj vsj (mrj−Σk̸=surkvkj))/Σjv^2sj\n",
    "    for iterations in range(i):\n",
    "        for r in range(1510):\n",
    "            for s in range(c):\n",
    "                u,v = update_u(u,v,N)\n",
    "        #update v using the formula y = (Σiuir(mis−Σk̸=ruikvks))/Σiu^2ir\n",
    "        for r in range(c):\n",
    "            for s in range(Row_df_array.shape[1]):\n",
    "                u,v = update_v(u,v,N)\n",
    "        uv = np.dot(u,v)\n",
    "        dif = uv-normal\n",
    "        print(\"Iteration Number: \",iterations )\n",
    "        MAE = mae(dif)\n",
    "        print('MAE',MAE)\n",
    "        #calculating RMSE\n",
    "        RMSE = rmse(dif)\n",
    "        print('RMSE=',RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "num_of_iterations = 75\n",
    "reguralization_factor = 0.05\n",
    "num_of_factors = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_table = pd.read_csv(filepath_or_buffer='./ml-1m/ratings.dat',\n",
    "                            sep='::', delimiter=None, header=0, names=['user_id', 'movie_id', 'rating', 'timestamp'] ,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import isnan\n",
    "\n",
    "def create_matrices(ratings):\n",
    "    \n",
    "    user_ids = ratings['user_id'].unique().tolist()\n",
    "    movie_ids = ratings['movie_id'].unique().tolist()\n",
    "\n",
    "    num_users = len(user_ids)\n",
    "    num_movies = len(movie_ids)\n",
    "\n",
    "    idx_user = range(num_users)\n",
    "    idx_movie = range(num_movies)\n",
    "\n",
    "    mapping_user = dict(zip(user_ids, idx_user))\n",
    "    mapping_movie = dict(zip(movie_ids, idx_movie))\n",
    "    \n",
    "    X = np.array(ratings.pivot(index='user_id',columns='movie_id', values='rating'))\n",
    "    U = np.random.uniform(-0.01, 0.01, (num_users, num_of_factors))\n",
    "    M = np.random.uniform(-0.01, 0.01, (num_of_factors, num_movies))\n",
    "\n",
    "    return [X, U, M, mapping_user, mapping_movie]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_der_reg(error, element):\n",
    "    deriv_reg = 2*error - reguralization_factor*element\n",
    "    return deriv_reg\n",
    "\n",
    "\n",
    "def calculate_predictions(X, U, M):\n",
    "    previous_rmse = 100000\n",
    "\n",
    "    for _ in range(num_of_iterations):\n",
    "        total_errors = []\n",
    "        for i, xi in enumerate(X):\n",
    "            for j, xj in enumerate(X[i]):\n",
    "\n",
    "                if isnan(X[i, j]):\n",
    "                    continue\n",
    "\n",
    "                pred_xij = np.dot(U[i, :], M[:, j])\n",
    "\n",
    "                error_xij = X[i, j] - pred_xij\n",
    "\n",
    "                total_errors.append(error_xij)\n",
    "\n",
    "                for k in range(num_of_factors):\n",
    "                    Uik = U[i, k] + learning_rate * \\\n",
    "                        (partial_der_reg(error_xij, M[k, j]))\n",
    "\n",
    "                    Mkj = M[k, j] + learning_rate * \\\n",
    "                        (partial_der_reg(error_xij, U[i, k]))\n",
    "\n",
    "                    U[i, k] = Uik\n",
    "                    M[k, j] = Mkj\n",
    "    \n",
    "        rmse = np.sqrt(np.sum(np.array(total_errors)**2))/len(total_errors)\n",
    "        if rmse == previous_rmse:\n",
    "            break\n",
    "\n",
    "        previous_rmse = rmse\n",
    "\n",
    "    return [U, M]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(predictions, actual):\n",
    "    total_errors = []\n",
    "    for i in range(len(actual)):\n",
    "        for j in range(len(actual[i])):\n",
    "            if not isnan(actual[i][j]):\n",
    "                error = predictions[i][j] - actual[i][j]\n",
    "                total_errors.append(error)\n",
    "                \n",
    "    return np.sqrt(np.sum(np.array(total_errors)**2))/len(total_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_test(predictions, actual, user_train_mapping, movie_train_mapping, user_test_mapping, movie_test_mapping):\n",
    "    total_errors = []\n",
    "    for u_id, u_index in user_test_mapping.items():\n",
    "      for m_id, m_index in movie_test_mapping.items():\n",
    "            if u_id in user_train_mapping and m_id in movie_train_mapping:\n",
    "                if not isnan(actual[u_index][m_index]):\n",
    "                    error = predictions[user_train_mapping[u_id]][movie_train_mapping[m_id]] - actual[u_index][m_index]\n",
    "                    total_errors.append(error)\n",
    "\n",
    "    return np.sqrt(np.sum(np.array(total_errors)**2))/len(total_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_data(Users, Movies):\n",
    "    predictions = np.matmul(Users, Movies)\n",
    "    \n",
    "    predictions[predictions > 5] = 5\n",
    "    predictions[predictions < 1] = 1\n",
    "     \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_matrix_factorization(data, learning_rate, iterations, regularization, num_factors):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    rmse_train_total = []\n",
    "    rmse_test_total = []\n",
    "    previous_test_rmse = 10000\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data = data.iloc[train_index]\n",
    "        test_data = data.iloc[test_index]\n",
    "        \n",
    "        X_train, U_train, M_train, user_train_mapping, movie_train_mapping = create_matrices(train_data)\n",
    "        \n",
    "        X_test, U_test, M_test, user_test_mapping, movie_test_mapping = create_matrices(test_data)\n",
    "\n",
    "        U_predicted, M_predicted = calculate_predictions(\n",
    "            X_train, U_train, M_train)\n",
    "\n",
    "        P_predicted = post_process_data(U_predicted, M_predicted)\n",
    "\n",
    "        rmse_train = calculate_rmse(P_predicted, X_train)\n",
    "        rmse_test = calculate_rmse_test(P_predicted, X_test, user_train_mapping, movie_train_mapping, user_test_mapping, movie_test_mapping)\n",
    "\n",
    "        if rmse_test < previous_test_rmse:\n",
    "            previous_test_rmse = rmse_test\n",
    "            U_best, M_best = U_predicted, M_predicted\n",
    "            user_train_mapping_best, movie_train_mapping_best = user_train_mapping, movie_train_mapping #maximos\n",
    "\n",
    "        rmse_train_total.append(rmse_train)\n",
    "        rmse_test_total.append(rmse_test)\n",
    "\n",
    "    return [U_best, M_best, rmse_train_total, rmse_test_total, user_train_mapping_best, movie_train_mapping_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, M, rmse_train, rmse_test, user_train_mapping_best, movie_train_mapping_best = k_fold_matrix_factorization(ratings_table, learning_rate, num_of_iterations, reguralization_factor, num_of_factors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67c387c2c5b8063b0f5207e4f2f5d1ecdb3788cfb68a74a0e938e4e5a4672a70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
